# Insight Quality Checklist

Use this checklist to evaluate research insights and ensure they're actionable, evidence-based, and valuable for design decision-making.

## What Makes a Good Insight?

A quality insight:
- ✅ Reveals underlying needs, not just surface observations
- ✅ Suggests opportunity space for design
- ✅ Based on patterns (3+ users), not one-offs
- ✅ Surprising or counter-intuitive
- ✅ Actionable (informs what to design)
- ✅ Specific and concrete
- ✅ Grounded in evidence (quotes, observations)

## Insight vs Observation

### Observation (What)
"8 out of 10 users emailed files to themselves"

### Insight (Why + So What)
"Users don't trust cloud storage or find it too complex; email is their universal, trusted tool for file access across devices"

**Transform observations into insights by asking**: "Why is this happening? What does this mean for design?"

---

## Quality Criteria Checklist

### 1. Evidence-Based

- [ ] **Based on actual research**: Comes from interviews, observations, or data
- [ ] **Multiple sources**: Seen in 3+ users (pattern, not outlier)
- [ ] **Specific examples**: Can point to quotes/behaviors supporting this
- [ ] **Not assumption**: Based on what users said/did, not what we think

**Test**: Can you cite evidence? If not, it's a hypothesis, not an insight.

**Example**:
- ❌ "Users want it faster" (assumption)
- ✅ "5 out of 8 users mentioned slow performance as reason for abandoning task" (evidence-based)

### 2. Reveals Underlying Need

- [ ] **Goes beyond surface**: Uncovers "why," not just "what"
- [ ] **Identifies motivation**: Explains user behavior
- [ ] **Shows root cause**: Gets to fundamental need
- [ ] **Human-centered**: Focuses on people, not just product

**Test**: Does it explain *why* users do something? If it only describes what they do, go deeper.

**Example**:
- ❌ "Users skip onboarding" (observation)
- ✅ "Users skip onboarding because they want immediate value and fear commitment to learning curve" (underlying need)

### 3. Actionable for Design

- [ ] **Suggests solutions**: Points toward design opportunities
- [ ] **Informs decisions**: Helps choose between options
- [ ] **Generates HMWs**: Can easily turn into "How Might We" questions
- [ ] **Inspires ideation**: Sparks solution ideas

**Test**: Can you immediately generate 3+ solution ideas from this insight?

**Example**:
- ❌ "Users are busy" (too vague to act on)
- ✅ "Users abandon tasks when they require >3 minutes uninterrupted time, preferring micro-interactions they can complete in seconds" (suggests bite-sized interactions)

### 4. Surprising or Non-Obvious

- [ ] **Challenges assumptions**: Contradicts what we expected
- [ ] **Reveals new perspective**: Something we didn't know
- [ ] **Not common knowledge**: Goes beyond obvious
- [ ] **Makes team say "Aha!"**: Creates moment of realization

**Test**: Did the team already know this? If yes, not an insight—it's confirmation.

**Example**:
- ❌ "Users want ease of use" (obvious)
- ✅ "Users prefer more clicks if each step feels safe, over fewer clicks that feel risky" (counter-intuitive)

### 5. Specific and Concrete

- [ ] **Clear and precise**: Not vague or generic
- [ ] **Contextual**: Includes when/where/how
- [ ] **Quantified if possible**: Numbers add weight
- [ ] **Memorable**: Easy to recall and reference

**Test**: Could this apply to any product/user? If yes, it's too generic.

**Example**:
- ❌ "Users want better experience" (vague)
- ✅ "During morning commute, users glance at app in 2-3 second bursts between stops, making dense information layouts unusable" (specific context)

---

## Insight Categories

### User Behavior Insights

- [ ] Describes what users actually do (not what they say)
- [ ] Includes context of behavior
- [ ] Explains trigger for behavior
- [ ] Notes frequency/consistency

**Example**: "When encountering error messages, users screenshot and text to colleagues rather than reading help docs, preferring human interpretation over official guidance"

### User Needs Insights

- [ ] Articulates underlying need
- [ ] Connects to user goals
- [ ] Shows intensity of need
- [ ] Differentiates from wants

**Example**: "Users need confidence they can undo actions to feel safe exploring features, even more than they need feature richness"

### User Mental Model Insights

- [ ] Reveals how users think system works
- [ ] Shows expectations vs reality
- [ ] Identifies metaphors users use
- [ ] Notes where confusion happens

**Example**: "Users expect file organization to mirror physical filing cabinets, using spatial memory and visual scanning, conflicting with tag-based systems"

### Emotional Insights

- [ ] Captures how users feel
- [ ] Identifies emotional triggers
- [ ] Shows intensity of emotion
- [ ] Connects emotion to behavior

**Example**: "Users feel anxious when forced to make irreversible decisions, leading to abandonment rather than risk-taking"

### Context Insights

- [ ] Describes environment/situation
- [ ] Shows how context influences behavior
- [ ] Identifies constraints in context
- [ ] Notes timing/location specifics

**Example**: "In open office environments, users avoid voice features due to social anxiety about disturbing neighbors, preferring slower text input for privacy"

---

## Common Insight Pitfalls

### Pitfall 1: Observations Disguised as Insights

❌ "Users click the wrong button"
✅ "Users click the wrong button because it visually resembles primary action button from competitor apps they use daily"

**Fix**: Add "because" or "which means" to go deeper

### Pitfall 2: Solutions Masquerading as Insights

❌ "We need to add a tutorial"
✅ "Users can't discover advanced features through exploration alone, requiring explicit guidance or progressive disclosure"

**Fix**: Describe the need/problem, not the solution

### Pitfall 3: Overgeneralization

❌ "Users hate complexity"
✅ "Power users embrace complexity in core workflows but resist it in infrequent setup tasks"

**Fix**: Add specificity about who, when, where

### Pitfall 4: Assumptions Presented as Insights

❌ "Young users prefer mobile"
✅ "In our research, 18-25 year-olds switched to mobile for on-the-go tasks but preferred desktop for complex workflows requiring multitasking"

**Fix**: Ground in actual research data

### Pitfall 5: One-Off Outliers

❌ "One user mentioned wanting dark mode"
✅ "7 of 10 users independently mentioned eye strain from bright interface during evening use, suggesting need for display adjustments"

**Fix**: Require 3+ users before calling it an insight

---

## Insight Grading Rubric

### Grade A: Excellent Insight

- ✅ Multiple evidence sources
- ✅ Reveals non-obvious need
- ✅ Highly actionable
- ✅ Surprising discovery
- ✅ Specific and concrete
- ✅ Memorable and quotable

**Example**: "Users don't forget passwords—they deliberately create forgettable ones to avoid security anxiety, then rely on reset flows as their actual auth method"

### Grade B: Good Insight

- ✅ Evidence-based
- ✅ Somewhat actionable
- ✅ Reveals need
- ⚠️ Not particularly surprising
- ⚠️ Could be more specific

**Example**: "Users prefer visual confirmation over text alerts when completing critical actions"

### Grade C: Weak Insight (Needs Work)

- ⚠️ Some evidence
- ⚠️ Somewhat obvious
- ⚠️ Vaguely actionable
- ❌ Not very surprising
- ❌ Generic

**Example**: "Users want faster loading times"

### Grade F: Not an Insight

- ❌ No evidence
- ❌ Just an observation or assumption
- ❌ Not actionable
- ❌ Completely obvious

**Example**: "Users use our product"

---

## Insight Refinement Process

### Step 1: Start with Observation

"7 users abandoned signup form at payment step"

### Step 2: Ask "Why?"

"Why did they abandon?"
→ "They said they weren't ready to commit"

### Step 3: Ask "Why?" Again (5 Whys)

"Why weren't they ready?"
→ "They hadn't experienced value yet"

### Step 4: Formulate Insight

"Users resist payment before experiencing product value, needing proof of worth before financial commitment, even for small amounts"

### Step 5: Make Actionable

"Which means we should provide immediate value demonstration before requesting payment"

### Step 6: Support with Evidence

Add quotes, stats, observed behaviors

---

## Insight Documentation Template

```
INSIGHT #[X]

**Statement**:
[One sentence insight]

**Evidence**:
- User quote 1: "[quote]"
- User quote 2: "[quote]"
- Observation: [what you saw]
- Frequency: [X out of Y users]

**So What** (Implications):
- [Design opportunity 1]
- [Design opportunity 2]

**HMW Questions**:
- How might we [address this need]?
- How might we [alternative approach]?

**Impact**: High / Medium / Low
**Confidence**: High / Medium / Low
```

---

## Quality Gate: Insight Review

Before calling something an insight and using it to inform design:

### Must Pass All:

- [ ] Can cite specific evidence (quotes, behaviors, data)
- [ ] Explains *why*, not just *what*
- [ ] Seen in 3+ users (or data shows pattern)
- [ ] Team can generate solution ideas from it
- [ ] More specific than "users want X to be better"

### Should Pass Most:

- [ ] Surprised the team (non-obvious)
- [ ] Challenges an assumption we had
- [ ] Includes context (when, where, how)
- [ ] Has emotional component
- [ ] Can be visualized or demonstrated

### Bonus Points:

- [ ] Quotable (team naturally references it)
- [ ] Reframes the problem space
- [ ] Connects multiple observations
- [ ] Reveals market opportunity

---

## Final Checkpoint

**Total insights captured**: _______

**Grade A insights (excellent)**: _______
**Grade B insights (good)**: _______
**Grade C insights (needs work)**: _______

**Target**: At least 5-10 Grade A or B insights to inform design

**If you have fewer than 5 quality insights**:
- ⚠️ Review research notes again
- ⚠️ Do affinity mapping with team
- ⚠️ Conduct additional research
- ⚠️ Go deeper on existing observations (5 Whys)

---

**Remember**: One excellent insight is worth more than ten mediocre observations. Quality over quantity. Take time to refine observations into actionable insights.
